{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_Fiction | Sarah.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNvpJkni3aUSBqcQhVGQlu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarahalyahya/SoftwareArt-Text/blob/main/Fiction_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeaH7QZ0ipwH"
      },
      "source": [
        "#Assignment 2 | Fiction | Behind the Unsent Texts\n",
        "###Idea\n",
        "My assignment was inpired by [\"The Unsent Project\" ](https://theunsentproject.com/). In our current day and time, we're so fast to judge an entire story based on a vague social media post, or in this case, text. So I wanted to play with the concept that there will always be more that we don't know. \n",
        "###Part 1 - Starting with the Unsent Project, Sentiment Analysis, and Scraping Positive/Negative Words\n",
        "For the first part, I scraped all the texts on the Unsent Project homepage by accessing the alt tag within the img tag, and picked one randomly. \n",
        "Then, I used TextBlob to check the text language and translate it if it isn't in english for the sake of having one language within the project. Then, I extracted the recipient name and applied the sentiment analysis to determine whether or not the text was positive or negative. \n",
        "Finally, I used the nltk library to extract specific verbs from the text that might inspire the content of the backstory excerpt that I was writing on my own. This was an interesting step, but it didn't achieve the effect I was expecting it to. \n",
        "\n",
        "After that, I used the polarity and scraped either a list of positive words or negative words based on the nature of the text, i.e. scraping a list of positive words if the text is positive. The number of adjectives scraped also depended on the extent to which the text was positive or negative. For this functionality, I had to create my own function as I realized that the range() function in python does not accept integers. By the end of the section, I had a list of adjectives that I intended to use in the final paragraph of my piece and to feed the GPT-2 \n",
        "Finally, I generated an excerpt that I thought would be helpful to start feeding to my GPT-2.\n",
        "###Part 2 - GPT-2\n",
        "[link](https://colab.research.google.com/drive/1rtJywTCkJsNJLPM-aA4pB1c40O1jD_AJ?usp=sharing)\n",
        "\n",
        "\n",
        "Here, I initially fed the GPT-2 the excerpt that was inspired by the extracted verbs, and used the extracted adjectives. Clearly, that wasn't enough tokens, so I started adding content scraped from Reddit and other online blogs as well as some that I drafted up myself. I slowly was realizing how the input needed to be altered and optimized for GPT-2. So I played around with the input, and decided to structure the output into:\n",
        "\n",
        "\n",
        "1.   Intro\n",
        "2.   Main Event / (e.g: in the case of a negative text, a break up)\n",
        "3.   Conclusion -- which I was planning to write on my own, and use the generated adjective in. \n",
        "\n",
        "\n",
        "So I created a compilation of \"Intro\" texts which were generally stories of how partners met and used these to train the GPT-2 to generate my first paragraph. Out of all the outputs, there was one that I thought worked well. I took a similar approach with the second part, where I fed GPT-2 a text file which contains multiple stories of conflict between two people. This part of the process was very much \"figure-out-as-you-go\", as I didn't expect to face as much trouble with GPT-2 as I did. The clear process I had in my head was becoming foggier, but I ended up managing to come up with a pretty realistic output. \n",
        "###Main Difficulties / Weaknesses\n",
        "I think in the midst of my confusion with GPT-2, the bridge between the first part of my work and the second slowly disappeared. I assumed that the outputs from Part 1 will greatly shape my GPT-2 input and output. Here, I think there's more that could've been done to bring both parts back together. Something that I can think of now is perhaps replacing the proper nouns with the name extracted from the text. Additionally, I hoped the output would be more \"alive\". The texts from the Unsent Project usually have a lot of emotion within them and having a more dynamic interaction with the user could have portrayed that better. \n",
        "###Lessons\n",
        "I think this assignment definitely familiarized me with working with GPT-2 better, and I will be putting more thought into the way I train my GPT-2 if I use it for our final assignment. Furthermore, it challenged my conceptual thinking and ability to brainstorm a lot. Even when my concept was changing due to the unexpected difficulties, I kept trying to tie it back to the main goal. \n",
        "\n",
        "###Conclusion\n",
        "This is was a challenging but exciting assignment to work on. I think as I learn more techniques and grow more comfortable with GPT-2 I would like to revisit it. There's a lot to look at and work with within 'The Unsent Project'!\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxbRDArxy-wA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e12679-c7d3-46f9-b931-338b855b80d9"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot77JD25y3WO"
      },
      "source": [
        "##REQUESTS\n",
        "unsentProjectLink = \"https://theunsentproject.com\"\n",
        "reqUnsentProject = requests.get(unsentProjectLink)\n",
        "negativeWordList = \"https://www.enchantedlearning.com/wordlist/negativewords.shtml\"\n",
        "reqNegative = requests.get(negativeWordList)\n",
        "\n",
        "positiveWordList = \"https://www.enchantedlearning.com/wordlist/positivewords.shtml\"\n",
        "reqPositive = requests.get(positiveWordList)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi1rzHZuy8UW",
        "outputId": "342cf7c7-6349-4449-a8ee-9a52022811b2"
      },
      "source": [
        "##SCRAPING THE UNSENT TEXTS + SENTIMENT ANALYSIS\n",
        "\n",
        "\n",
        "unsentProjSoup = BeautifulSoup(reqUnsentProject.content, 'html.parser')\n",
        "texts = []\n",
        "#the content on the website is presented in image, but the text content is present in the html alt tag within the img tag\n",
        "for i in unsentProjSoup.find_all('img', alt= True):\n",
        "  texts.append(i['alt'] + \"\\n\")\n",
        "\n",
        "\n",
        "#initializing polarity as 0.0 to use in the next while statement\n",
        "polarity = 0.0\n",
        "\n",
        "\n",
        "#this condition, \"polarity == 0.0\", is to avoid the texts that return 0.0 as polarity, as that disrupts the program \n",
        "while polarity == 0.0:\n",
        "  ##picks a random text\n",
        "  chosenTextIndex = random.randint(0,len(texts)-1)\n",
        "  unsentText = (texts[chosenTextIndex])\n",
        "  ##creating a textblob to use translation later\n",
        "  sentAnalysisText = TextBlob(unsentText)\n",
        "  #removing the first part, \"To: X -\", as it will always return english as the language and won't translate the content\n",
        "  forTranslation = sentAnalysisText.split(\"-\", 1)\n",
        "\n",
        "  #checks if the text is in english, if not, it translates it to english\n",
        "  if (forTranslation[1].detect_language() != 'en'):\n",
        "    \n",
        "      forTranslation[1] = forTranslation[1].translate(to='en')\n",
        "\n",
        "  #joins again, as a string   \n",
        "  unsentText = '- '.join(forTranslation)\n",
        "\n",
        "  #separate variable for TextBlob, for sentiment analysis\n",
        "  sentAnalysisText = TextBlob(unsentText)\n",
        "  \n",
        "  #measuring polarity of text content\n",
        "  polarity = sentAnalysisText.sentiment.polarity \n",
        "\n",
        "#extracting name from the text\n",
        "uTextList = unsentText.split()\n",
        "name = uTextList[1]\n",
        "\n",
        "print(name)\n",
        "print(sentAnalysisText)  \n",
        "print(polarity)\n",
        "\n",
        "##empty lists for different types of verbs extracted from the text, could help add context to the GPT text\n",
        "basicVerbs = []\n",
        "pastVerbs = []\n",
        "pastParticipleVerbs = []\n",
        "\n",
        "##avoiding basic verbs that don't add to context\n",
        "toAvoid = ['be','was','were','been','have','has','had', 'am',\"'re\",'are','do']\n",
        "\n",
        "##goes through the text and checks for verbs that can be included in the lists\n",
        "for x in range (len(sentAnalysisText.tags)):\n",
        "  if sentAnalysisText.tags[x][1] == 'VB' and sentAnalysisText.tags[x][0] not in toAvoid and sentAnalysisText.tags[x][0] != name:\n",
        "    basicVerbs.append(sentAnalysisText.tags[x][0])\n",
        "  elif sentAnalysisText.tags[x][1] == 'VBD' and sentAnalysisText.tags[x][0] not in toAvoid:\n",
        "    pastVerbs.append(sentAnalysisText.tags[x][0])\n",
        "  elif sentAnalysisText.tags[x][1] == 'VBP' and sentAnalysisText.tags[x][0] not in toAvoid:\n",
        "    pastParticipleVerbs.append(sentAnalysisText.tags[x][0])\n",
        "\n",
        "\n",
        "#print(basicVerbs)\n",
        "#print(pastVerbs)\n",
        "#print(pastParticipleVerbs)\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nicolly\n",
            "To: Nicolly - if you hadn’t done that we’d be fine, I hope you’re sorry for that\n",
            "-0.04166666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LyvMewzISwg",
        "outputId": "275255d1-af27-4450-9789-4fc23d526386"
      },
      "source": [
        "##SCRAPING A NUMBER OF  POSITIVE OR NEGATIVE WORDS DEPENDING ON POLARITY \n",
        "\n",
        "##checking if positive or negative should be scraped\n",
        "if polarity > 0:\n",
        "  wordSoup = BeautifulSoup(reqPositive.content, 'html.parser')\n",
        "elif polarity < 0:\n",
        "    wordSoup = BeautifulSoup(reqNegative.content, 'html.parser')\n",
        "\n",
        "#finding all words\n",
        "adjectivesTemp = wordSoup.find_all('div', class_='wordlist-item')\n",
        "adjectives=[]\n",
        "\n",
        "##affing them to a list\n",
        "for x in range(len(adjectivesTemp)):\n",
        "  adjectives.append(adjectivesTemp[x].text)\n",
        "\n",
        "\n",
        "\n",
        "##creating an empty list for adjectives we want to use in the sample text for GPT-2\n",
        "adjectivesToUse = []\n",
        "count = 0\n",
        "\n",
        "##I realized that the range function in python does not work for floats, so I created functions to solve that issue\n",
        "def checkRange1(value):\n",
        "  if 0.01 <= value < 0.4:\n",
        "    return True \n",
        "\n",
        "def checkRange2(value):\n",
        "  if 0.4 <= value <= 1.0:\n",
        "    return True \n",
        "\n",
        "def checkRange3(value):\n",
        "  if -0.01 >= value > -0.4:\n",
        "    return True \n",
        "\n",
        "def checkRange4(value):\n",
        "  if -0.4 >= value >= -1.1:\n",
        "    return True \n",
        "\n",
        "##depending on HOW positive/negative the text is, either 5 or 10 adjectives are chosen\n",
        "if checkRange1(polarity) and not checkRange2(polarity) and not checkRange3(polarity) and not checkRange4(polarity):\n",
        "  while count !=5:\n",
        "    adjectivesToUse.append(adjectives[random.randint(0,len(adjectives)-1)])\n",
        "    count += 1\n",
        "elif checkRange2(polarity) and not checkRange1(polarity) and not checkRange3(polarity) and not checkRange4(polarity):\n",
        "  while count !=10:\n",
        "    adjectivesToUse.append(adjectives[random.randint(0,len(adjectives)-1)])\n",
        "    count += 1\n",
        "elif checkRange3(polarity) and not checkRange4(polarity) and not checkRange2(polarity) and not checkRange1(polarity):\n",
        "  while count !=5:\n",
        "    adjectivesToUse.append(adjectives[random.randint(0,len(adjectives)-1)])\n",
        "    count += 1\n",
        "elif checkRange4(polarity) and not checkRange3(polarity) and not checkRange2(polarity) and not checkRange1(polarity):\n",
        "  while count !=10:\n",
        "    adjectivesToUse.append(adjectives[random.randint(0,len(adjectives)-1)])\n",
        "    count += 1\n",
        "\n",
        "\n",
        "\n",
        "print(adjectivesToUse)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cold-hearted', 'lousy', 'dismal', 'shocking', 'ugly']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGxGn8EG3HT_",
        "outputId": "c53e7a6f-d5b2-4850-d16c-86074400fd1a"
      },
      "source": [
        "sampleText = \"This is the backstory of my text to %s and our time together. \" %(name)\n",
        "\n",
        "\n",
        "if polarity > 0:\n",
        "  sampleText = sampleText + '''[BACK STORY] We originally met in a park, I was sitting on a bench and they came and sat next to me and we just started talking for hours and hours about nothing and everything.\n",
        "  After that, I got their number and we went out on our first date a few days after. It was amazing. We went to this delicious Japanese restaurant downtown and ordered too much food. \n",
        "  Then after a few dates, I asked them to become my partner. It was the best decision I made!   \n",
        "  [MAIN EVENT] They helped me through so much. I was in a really dark phase in my life and they would encourage me to stay strong and talk through all my problems. We made the best memories together, I will forever cherish them. \n",
        "  I specifically remember our camping trip together, we were sitting next to a small bonfire, roasting marshmallows and talking about life. We were playing our favorite songs and laughing together. I think this is when I was sure I wanted them in my life forever. \n",
        "  [CURRENT STATE]  We just moved in together in a cozy apartment with our dog, Pluto. We're slowly building our life together and growing. I just got a new job, and they just got promoted. \n",
        "   So, yeah, they're the best thing that ever happened to me. They are my soulmate and that's why I decided to send them that text.'''\n",
        "\n",
        "if polarity < 0:\n",
        "  sampleText = sampleText + '''[BACK STORY] We originally met in a park, I was sitting on a bench and and they came and sat next to me. We went on our first date a few days after, and I guess we clicked at first but that didn't last for long.\n",
        "  I noticed a few red flags in our first date, like how they were constantly interrupting me and talking over me. I dismissed them, I thought: \"maybe they're just too excited, these things don't matter!\" Our dates grew more and more boring and insufferable with time. \n",
        "  I wish someone could give me back all the hours I wasted on those awkward dinners that were full of tension. It was clear we just did not enjoy each other's company like we should. \n",
        "  [MAIN EVENT] I still put up with them. I believed we can fix it and make everything better. I was so foolish to believe that, especially after all the horrible things they've done to me. They lied, cheated, and just treated me in the worst way possible.\n",
        "  One day, I looked at their phone and found texts from someone else. Disgusting. I couldn't believe this, that was the final straw, I realized I really didn't need to suffer through it anymore.\n",
        "  [CURRENT STATE] I confronted them, yelled at them for hours...I mean how could they do this to me?! We ended up breaking up and I would say we're on bad terms now. It's so hostile and anytime I see them I feel like suffocating.\n",
        "  There's no one I hate more and that's why I decided to send them that text.'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(sampleText)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the backstory of my text to Nicolly and our time together. [BACK STORY] We originally met in a park, I was sitting on a bench and and they came and sat next to me. We went on our first date a few days after, and I guess we clicked at first but that didn't last for long.\n",
            "  I noticed a few red flags in our first date, like how they were constantly interrupting me and talking over me. I dismissed them, I thought: \"maybe they're just too excited, these things don't matter!\" Our dates grew more and more boring and insufferable with time. \n",
            "  I wish someone could give me back all the hours I wasted on those awkward dinners that were full of tension. It was clear we just did not enjoy each other's company like we should. \n",
            "  [MAIN EVENT] I still put up with them. I believed we can fix it and make everything better. I was so foolish to believe that, especially after all the horrible things they've done to me. They lied, cheated, and just treated me in the worst way possible.\n",
            "  One day, I looked at their phone and found texts from someone else. Disgusting. I couldn't believe this, that was the final straw, I realized I really didn't need to suffer through it anymore.\n",
            "  [CURRENT STATE] I confronted them, yelled at them for hours...I mean how could they do this to me?! We ended up breaking up and I would say we're on bad terms now. It's so hostile and anytime I see them I feel like suffocating.\n",
            "  There's no one I hate more and that's why I decided to send them that text.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm3pvO7y3uXs"
      },
      "source": [
        "##from GPT\n",
        "###Chosen Text for Intro\n",
        "\"We went to camp together, and we both had a liking for this local band who had made it relatively big, so for her birthday, I got two tickets to see them at a homecoming show as a way of asking her out. I put the tickets in her card and wrote some crap about looking forward to taking her.\"\n",
        "###Chosen Text for Second Paragraph\n",
        "\"As soon as we went there she started questioning me about various things, she started doubting me and there after we developed lots of misunderstanding between us. It was then when i realised that it wasn't working anymore and rather than discussing situations with her i made a quick decision of break up. I still remember that day she was begging me to stay. All she was asking me to not to leave her for she wanted me and just me.\" "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRgtR3ZJ3zZP"
      },
      "source": [
        "##Generating the Final Paragraph\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEpACSom4KFU",
        "outputId": "064ca5b0-6aaf-4c7b-b41f-3ca1ba7cc3b7"
      },
      "source": [
        "finalPara =  \"Our relationship can easily be described as: \"\n",
        "for adjective in adjectivesToUse:\n",
        "  finalPara =  finalPara + adjective + \", \"\n",
        "\n",
        "finalPara = finalPara + \"I think it just never would have worked. We tried really hard but it just wasn't meant to be. So we never talked again, and I decided to send her this text through the Unsent Project. I don't know if she'll ever receive it, or read it...I'm not sure I care. Yeah, that's it, that's our story.\"\n",
        "print(finalPara)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our relationship can easily be described as: cold-hearted, lousy, dismal, shocking, ugly, I think it just never would have worked. We tried really hard but it just wasn't meant to be. So we never talked again, and I decided to send her this text through the Unsent Project. I don't know if she'll ever receive it, or read it...I'm not sure I care. Yeah, that's it, that's our story.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of4kersh6kaQ"
      },
      "source": [
        "##Final Paragraph\n",
        "Our relationship can easily be described as: cold-hearted, lousy, dismal, shocking, ugly, I think it just never would have worked. We tried really hard but it just wasn't meant to be. So we never talked again, and I decided to send her this text through the Unsent Project. I don't know if she'll ever receive it, or read it...I'm not sure I care. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP5y7Qy08gnX"
      },
      "source": [
        "##Full Back Story\n",
        " We went to camp together, and we both had a liking for this local band who had made it relatively big, so for her birthday, I got two tickets to see them at a homecoming show as a way of asking her out. I put the tickets in her card and wrote some crap about looking forward to taking her.\n",
        "  \n",
        "  As soon as we went there she started questioning me about various things, she started doubting me and there after we developed lots of misunderstanding between us. It was then when i realised that it wasn't working anymore and rather than discussing situations with her i made a quick decision of break up. I still remember that day she was begging me to stay. All she was asking me to not to leave her for she wanted me and just me.\n",
        "  \n",
        "Our relationship can easily be described as: cold-hearted, lousy, dismal, shocking, ugly, I think it just never would have worked. We tried really hard but it just wasn't meant to be. So we never talked again, and I decided to send her this text through the Unsent Project. I don't know if she'll ever receive it, or read it...I'm not sure I care.\n"
      ]
    }
  ]
}